{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"food_type_clustering.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1N--ZTlPMr6LEg_oQfiAYxXPQE9jU5zOz","authorship_tag":"ABX9TyOqHqYdhOFPGkS04I4C4+ez"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"UMTPdVhUQrVP","executionInfo":{"status":"ok","timestamp":1602661104415,"user_tz":-480,"elapsed":1010,"user":{"displayName":"Tommy Yong","photoUrl":"","userId":"06947437094583181843"}},"outputId":"4b6ede82-e5d3-4d67-e95b-90264e89a39c","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["#This file is for visualizing web scraped data to understand food cateogry subtypes that can be derived from user reviews.\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import Normalizer\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.pipeline import make_pipeline\n","from sklearn.cluster import KMeans\n","from sklearn import metrics\n","import re\n","import string\n","import time\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"Prd5v7s-RWjt"},"source":["##Constants\n","mystopwords=stopwords.words(\"english\")+['singapore', \n","'holiday', 'sister', 'brother', 'kid', 'generally', 'european', \n","'typically', 'recommend', 'recommended', 'reasonable', 'like', 'liked',\n","'french', 'quite', 'back', 'definitely', 'place', 'food', 'sand', 'bay', \n","'afternoon', 'home', 'lunch', 'dinner', 'roof', 'layout', 'restaurant',\n","'situation', 'set', 'email', 'rooftop', 'bar', 'really', 'good',\n","'work', 'music', 'marriot', 'skyline', 'hotel', 'impeccable', 'fullerton',\n","'classy', 'feel', 'presented', 'present', 'well', 'explaining', 'decoration',\n","'wife', 'husband', 'friend', 'perfectly', 'limited', 'called', 'call',\n","'delight', 'arrive', 'otherwise', 'unfortunately', 'enjoyable',\n","'seemed', 'managed', 'read', 'indeed', 'stay', 'great', 'plus',\n","'better', 'front', 'recently', 'floor', 'friday', 'monday', 'tuesday',\n","'wednesday', 'thursday', 'saturday', 'sunday', 'weekend', 'weekends',\n","'weekdays', 'weekday', 'often', 'wait', 'waited','seat', 'seated',\n","'week', 'ordering', 'something', 'next', 'know', 'known',\n","'helped', 'entrance', 'also', 'enough', 'reservation', 'going',\n","'go', 'need', 'coming', 'etc', 'sit', 'disappointing', 'certainly',\n","'able', 'gave', 'give', 'including', 'seems', 'table', 'must',\n","'try', 'time', 'would', 'will', 'even', 'many', 'especially', 'though',\n","'although', 'must try', 'year', 'outside', 'however', 'around', 'group',\n","'want', 'take', 'overall', 'took', 'surprised', 'recommendation',\n","'okay', 'let', 'either', 'bring', 'helpful', 'crowd', 'yes', 'no',\n","'except', 'soon', 'remember', 'business', 'queue', 'everyone',\n","'chose', 'station', 'fact', 'keep', 'anything', 'within','sgd',\n","'saw', 'expectation', 'due', 'stop', 'counter', 'corner', 'mine',\n","'check', 'hit', 'similar', 'despite', 'note', 'reasonably', 'impressed',\n","'impress', 'particularly', 'highlight', 'later', 'late', 'based',\n","'totally', 'heard', 'city', 'colleague', 'across', 'space', 'leave',\n","'world', 'avoid','various','tell', 'told', 'ended', 'town', 'change',\n","'personally', 'making', 'make', 'typical', 'help', 'outstanding',\n","'surprisingly', 'surprised', 'upon', 'into','nearby', 'please',\n","'pleased', 'pleasing', 'disappoint','followed','sharing', 'taken',\n","'took', 'take', 'among', 'amongst', 'sitting', 'sell', 'deal', 'party',\n","'one', 'two', 'menu','visit','get','view', 'marina', 'amazing',\n","'amaze', 'amazed', 'child', 'class', 'boy', 'complain', 'could',\n","'busy', 'choose', 'came', 'arrival', 'departure', 'could get',\n","'court', 'complimentary', 'boyfriend', 'girlfriend', 'charged',\n","'booking', 'book', 'brought', 'actually', 'absolutely', 'accompanied',\n","'addition', 'across', 'long', 'always', 'absolute', 'advance',\n","'acceptable', 'bright', 'ask', 'asking', 'base', 'almost', 'anyone',\n","'compare', 'compared', 'behind', 'case', 'country', 'away', 'arrangement',\n","'concept', 'apparently', 'anywhere', 'compliment', 'certain', 'available',\n","'charming', 'catch', 'attended', 'comfortable', 'ceiling', 'basically',\n","'booked', 'charge', 'card', 'combination', 'common', 'celebration', \n","'closed', 'clarke', 'quay', 'chain', 'arrived', 'cheerful', 'clarke quay',\n","'average', 'carte', 'craving', 'branch', 'credit card', 'bought', 'bad',\n","'constantly', 'considering', 'believe', 'best', 'celebrate',\n","'chope', 'beautiful', 'buy', 'asked', 'anyway', 'ambiance', 'anniversary'\n","'ahead', 'additional', 'advice', 'abit',\n","'adult', 'alright', 'another', 'checking', 'birthday', 'bother',\n","'credit', 'compare', 'centre', '']\n","\n","WNlemma = nltk.WordNetLemmatizer()\n","num_clusters = 5\n","vectorizer = TfidfVectorizer(max_df=0.3, max_features=6000,\n","                             min_df=5, stop_words=mystopwords,\n","                             use_idf=True, ngram_range=(1,3))\n","clusterHolder1 = []\n","clusterHolder2 = []\n","\n","##Functions\n","def pre_process(text):\n","    tokens = nltk.word_tokenize(text)\n","    tokens=[ WNlemma.lemmatize(t.lower()) for t in tokens]\n","    tokens=[ t for t in tokens if t not in mystopwords]\n","    tokens=[ t for t in tokens if False == t.isdigit()]\n","    tokens=[ t for t in tokens if False == containsNumeric(t)]\n","    tokens=[ t for t in tokens if True == t.isalpha()]\n","    tokens=[ t for t in tokens if t not in string.punctuation]\n","    tokens = [ t for t in tokens if len(t) >= 3 ]\n","    text_after_process=\" \".join(tokens)\n","    return(text_after_process)\n","\n","def print_terms(cm, num):\n","    original_space_centroids = cm.cluster_centers_\n","    order_centroids = original_space_centroids.argsort()[:, ::-1]\n","    terms = vectorizer.get_feature_names()\n","    for i in range(num):\n","        print(\"Cluster %d:\" % i, end='')\n","        for ind in order_centroids[i, :10]:\n","            print(' %s' % terms[ind], end='')\n","        print()\n","\n","def containsNumeric(text):\n","    if text is not None:\n","        return any(str.isdigit(c) for c in text)\n","    else:\n","        return True\n","\n","def saveClusterValues(model, clusterNum, array):\n","    original_space_centroids = model.cluster_centers_\n","    order_centroids = original_space_centroids.argsort()[:, ::-1]\n","    terms = vectorizer.get_feature_names()\n","    for ind in order_centroids[clusterNum, :]:\n","        array.append(terms[ind])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMHMCZsRRcgg","executionInfo":{"status":"ok","timestamp":1602661398405,"user_tz":-480,"elapsed":294982,"user":{"displayName":"Tommy Yong","photoUrl":"","userId":"06947437094583181843"}},"outputId":"2991b4e0-b179-40f5-e3a4-18b93bf903f0","colab":{"base_uri":"https://localhost:8080/","height":921}},"source":["data_files = '../data/'\n","data = pd.read_csv('/content/drive/My Drive/PLP Sem 4/data.csv', encoding='unicode_escape')\n","data.groupby('restaurant')\n","text = data['Review']\n","tokens = text.apply(pre_process)\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Review</th>\n","      <th>address</th>\n","      <th>author</th>\n","      <th>author_loc</th>\n","      <th>date</th>\n","      <th>origin</th>\n","      <th>rating</th>\n","      <th>restaurant</th>\n","      <th>type</th>\n","      <th>region</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Visited on a day without Unagi *0*Location: 4/...</td>\n","      <td>7500A Beach Road The Plaza #B1-310, The Plaza,...</td>\n","      <td>ML-SG-001</td>\n","      <td>Singapore, Singapore</td>\n","      <td>8/10/2020</td>\n","      <td>TripAdvisor</td>\n","      <td>2</td>\n","      <td>Uni Gallery by OosterBay</td>\n","      <td>Japanese,Sushi,Asian</td>\n","      <td>CENTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Since my visit to Sushi Kimura, I had this str...</td>\n","      <td>7500A Beach Road The Plaza #B1-310, The Plaza,...</td>\n","      <td>morsels-of-delice</td>\n","      <td>Singapore, Singapore</td>\n","      <td>10/30/2019</td>\n","      <td>TripAdvisor</td>\n","      <td>5</td>\n","      <td>Uni Gallery by OosterBay</td>\n","      <td>Japanese,Sushi,Asian</td>\n","      <td>CENTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>We enjoyed our meal very much. The uni platter...</td>\n","      <td>7500A Beach Road The Plaza #B1-310, The Plaza,...</td>\n","      <td>baolover</td>\n","      <td>Singapore, Singapore</td>\n","      <td>7/26/2020</td>\n","      <td>TripAdvisor</td>\n","      <td>5</td>\n","      <td>Uni Gallery by OosterBay</td>\n","      <td>Japanese,Sushi,Asian</td>\n","      <td>CENTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Came here during Stage 2 CB period , Oosterbay...</td>\n","      <td>7500A Beach Road The Plaza #B1-310, The Plaza,...</td>\n","      <td>Tan T</td>\n","      <td>Singapore, Singapore</td>\n","      <td>7/23/2020</td>\n","      <td>TripAdvisor</td>\n","      <td>5</td>\n","      <td>Uni Gallery by OosterBay</td>\n","      <td>Japanese,Sushi,Asian</td>\n","      <td>CENTRAL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A highly recommended good Japanese restaurant ...</td>\n","      <td>7500A Beach Road The Plaza #B1-310, The Plaza,...</td>\n","      <td>WSJJ</td>\n","      <td>Singapore, Singapore</td>\n","      <td>7/3/2020</td>\n","      <td>TripAdvisor</td>\n","      <td>5</td>\n","      <td>Uni Gallery by OosterBay</td>\n","      <td>Japanese,Sushi,Asian</td>\n","      <td>CENTRAL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  ...   region\n","0           0  ...  CENTRAL\n","1           1  ...  CENTRAL\n","2           2  ...  CENTRAL\n","3           3  ...  CENTRAL\n","4           4  ...  CENTRAL\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"KSI9wOrTQ2oK","executionInfo":{"status":"ok","timestamp":1602665427394,"user_tz":-480,"elapsed":4323957,"user":{"displayName":"Tommy Yong","photoUrl":"","userId":"06947437094583181843"}},"outputId":"b86e881d-577c-4992-cd6f-c678feeb09ae","colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["X = vectorizer.fit_transform(tokens)\n","km1 = KMeans(n_clusters=num_clusters, init='k-means++', max_iter=1000)\n","\n","print(\"Fitting to k-means model...\")\n","time_start = time.time()\n","\n","km1.fit(X)\n","print('Fitting done! Time elapsed: {} seconds'.format(time.time()-time_start))\n","\n","print(\"Coefficient for \"+str(num_clusters)+\" clusters: %0.3f\"\n","     % metrics.silhouette_score(X, km1.labels_))\n","\n","labels, counts = np.unique(km1.labels_[km1.labels_>=0], return_counts=True)\n","print (labels)\n","print (counts)\n","print_terms(km1, num_clusters)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting to k-means model...\n","Fitting done! Time elapsed: 2849.6138598918915 seconds\n","Coefficient for 5 clusters: 0.004\n","[0 1 2 3 4]\n","[134749  18327  26296   7202  15959]\n","Cluster 0: dish price experience delicious meal chicken taste drink quality ordered\n","Cluster 1: nice ambience nice ambience staff drink nice service price atmosphere service nice wine\n","Cluster 2: staff friendly staff friendly attentive service staff friendly staff experience staff attentive delicious ambience\n","Cluster 3: crab chilli chilli crab pepper chili pepper crab chili crab seafood black pepper black\n","Cluster 4: excellent excellent service service excellent staff experience wine quality ambience highly dish\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBXgrOjIW9i1"},"source":["df = pd.DataFrame(clusterHolder1)\n","df.to_csv('/content/drive/My Drive/PLP Sem 4/results.csv', index=False, header=['Food_SubType'])"],"execution_count":null,"outputs":[]}]}